<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MIOpen: RNN</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MIOpen
   &#160;<span id="projectnumber">v5.4.4</span>
   </div>
   <div id="projectbrief">AMD&#39;s Machine Intelligence Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">RNN</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:ga016f266507f199def908fe39c43d7877"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a> { <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga016f266507f199def908fe39c43d7877af714eb36c96ca365b643e7e8417c10cc">miopenRNNRELU</a> = 0
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga016f266507f199def908fe39c43d7877a1d43e2e3151aa1266cc10e8623c0a32b">miopenRNNTANH</a> = 1
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga016f266507f199def908fe39c43d7877a97804b8e078f16b327e50e5554df970c">miopenLSTM</a> = 2
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga016f266507f199def908fe39c43d7877aa13bc340d91e98e610e92b75e5928a66">miopenGRU</a> = 3
<br />
 }</td></tr>
<tr class="separator:ga016f266507f199def908fe39c43d7877"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga11808e1b616d9b9d7e6c701986783af7"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a> { <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga11808e1b616d9b9d7e6c701986783af7a168f261ee3dc35ea3fe636c644610c2f">miopenRNNlinear</a> = 0
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga11808e1b616d9b9d7e6c701986783af7a99c1caff2a69fb37d964fb3692c989da">miopenRNNskip</a> = 1
<br />
 }</td></tr>
<tr class="separator:ga11808e1b616d9b9d7e6c701986783af7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6bca6bf2c239cb387d99a07cb6b331c4"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a> { <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga6bca6bf2c239cb387d99a07cb6b331c4aee4782e7cebfb009314cdd6c695a5b90">miopenRNNdefault</a> = 0
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga6bca6bf2c239cb387d99a07cb6b331c4a2dfd71a22376cd8b11bd1a1b4fe46996">miopenRNNfundamental</a>
<br />
 }</td></tr>
<tr class="separator:ga6bca6bf2c239cb387d99a07cb6b331c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3c7adae8941033d266f1d5e029504c38"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a> { <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga3c7adae8941033d266f1d5e029504c38a78752802fd2c7248fd4fdddbf613264b">miopenRNNunidirection</a> = 0
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga3c7adae8941033d266f1d5e029504c38a2f0f99690655d0df5ca16bd5011908ea">miopenRNNbidirection</a> = 1
<br />
 }</td></tr>
<tr class="separator:ga3c7adae8941033d266f1d5e029504c38"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga47b037e570937a567de38e8898a99f37"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a> { <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga47b037e570937a567de38e8898a99f37a2eb8172730ba33866564865fe4e2d7ea">miopenRNNNoBias</a> = 0
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga47b037e570937a567de38e8898a99f37a14fd5be6ddb03ef2d81d27ff8a868d10">miopenRNNwithBias</a> = 1
<br />
 }</td></tr>
<tr class="separator:ga47b037e570937a567de38e8898a99f37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac7f800028b5634cb08aa191fa6ee0d2a"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gac7f800028b5634cb08aa191fa6ee0d2a">miopenRNNGEMMalgoMode_t</a> { <a class="el" href="group___r_n_n.html#ggac7f800028b5634cb08aa191fa6ee0d2aa5803419df2c12a2ea02b7560a54ebee7">miopenRNNAlgoGEMM</a> = 0
 }</td></tr>
<tr class="separator:gac7f800028b5634cb08aa191fa6ee0d2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaeb0b6dbeefb776e9b663c66a247a7121"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gaeb0b6dbeefb776e9b663c66a247a7121">miopenRNNPaddingMode_t</a> { <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#ggaeb0b6dbeefb776e9b663c66a247a7121a280a03179097c1c96d3b26f4f25543e2">miopenRNNIONotPadded</a> = 0
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#ggaeb0b6dbeefb776e9b663c66a247a7121a0d1f9de9cb101771b9bb572ddfa2f2ef">miopenRNNIOWithPadding</a> = 1
<br />
 }</td></tr>
<tr class="separator:gaeb0b6dbeefb776e9b663c66a247a7121"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9e0d9408f321de068cc30ad5a7de778b"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga9e0d9408f321de068cc30ad5a7de778b">miopenRNNFWDMode_t</a> { <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga9e0d9408f321de068cc30ad5a7de778ba2a424459293f8f7a74ab45b70a902f4e">miopenRNNTraining</a> = 0
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga9e0d9408f321de068cc30ad5a7de778ba2e5ed4c109920976110cdc7c7fd4cefc">miopenRNNInference</a> = 1
<br />
 }</td></tr>
<tr class="separator:ga9e0d9408f321de068cc30ad5a7de778b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga637e3f078445cce6869966a46e1a486f"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga637e3f078445cce6869966a46e1a486f">miopenRNNBaseLayout_t</a> { <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga637e3f078445cce6869966a46e1a486fae9bb9aaef77070d408758f4d2dbef44d">miopenRNNDataUnknownLayout</a> = 0
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga637e3f078445cce6869966a46e1a486fa956d8d35f87c4aa06a4f9d5561aef5f1">miopenRNNDataSeqMajorNotPadded</a> = 1
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga637e3f078445cce6869966a46e1a486fa04fbe3dee060a5d78eb007028468134f">miopenRNNDataSeqMajorPadded</a> = 2
, <br />
&#160;&#160;<a class="el" href="group___r_n_n.html#gga637e3f078445cce6869966a46e1a486fad5db52f1c42231b13de635892872c931">miopenRNNDataBatchMajorPadded</a> = 3
<br />
 }</td></tr>
<tr class="separator:ga637e3f078445cce6869966a46e1a486f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga781cb4cafc3e631e189a0ec014a2729f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga781cb4cafc3e631e189a0ec014a2729f">MIOPEN_DECLARE_OBJECT</a> (miopenRNNDescriptor)</td></tr>
<tr class="memdesc:ga781cb4cafc3e631e189a0ec014a2729f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates the miopenRNNDescriptor_t type.  <a href="group___r_n_n.html#ga781cb4cafc3e631e189a0ec014a2729f">More...</a><br /></td></tr>
<tr class="separator:ga781cb4cafc3e631e189a0ec014a2729f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab6af15d94b2e0932873142d55aa239b4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gab6af15d94b2e0932873142d55aa239b4">miopenCreateRNNDescriptor</a> (miopenRNNDescriptor_t *rnnDesc)</td></tr>
<tr class="memdesc:gab6af15d94b2e0932873142d55aa239b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a RNN layer Descriptor.  <a href="group___r_n_n.html#gab6af15d94b2e0932873142d55aa239b4">More...</a><br /></td></tr>
<tr class="separator:gab6af15d94b2e0932873142d55aa239b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6ac11f7ee823327d80e1b0ebc6774b3f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga6ac11f7ee823327d80e1b0ebc6774b3f">miopenGetRNNDescriptor</a> (miopenRNNDescriptor_t rnnDesc, <a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a> *rnnMode, <a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a> *algoMode, <a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a> *inputMode, <a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a> *dirMode, <a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a> *biasMode, int *hiddenSize, int *layer)</td></tr>
<tr class="memdesc:ga6ac11f7ee823327d80e1b0ebc6774b3f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves a RNN layer descriptor's details.  <a href="group___r_n_n.html#ga6ac11f7ee823327d80e1b0ebc6774b3f">More...</a><br /></td></tr>
<tr class="separator:ga6ac11f7ee823327d80e1b0ebc6774b3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga102a6710811b4662eee1c3f2858b3498"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga102a6710811b4662eee1c3f2858b3498">miopenGetRNNDescriptor_V2</a> (miopenRNNDescriptor_t rnnDesc, int *hiddenSize, int *layer, miopenDropoutDescriptor_t *dropoutDesc, <a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a> *inputMode, <a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a> *dirMode, <a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a> *rnnMode, <a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a> *biasMode, <a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a> *algoMode, <a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> *dataType)</td></tr>
<tr class="memdesc:ga102a6710811b4662eee1c3f2858b3498"><td class="mdescLeft">&#160;</td><td class="mdescRight">Retrieves a RNN layer descriptor's details version 2. This version enables retrieving information of the dropout descriptor of the rnn descriptor.  <a href="group___r_n_n.html#ga102a6710811b4662eee1c3f2858b3498">More...</a><br /></td></tr>
<tr class="separator:ga102a6710811b4662eee1c3f2858b3498"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf5675f82ade15ca38b890f6ea4d035b5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gaf5675f82ade15ca38b890f6ea4d035b5">miopenDestroyRNNDescriptor</a> (miopenRNNDescriptor_t rnnDesc)</td></tr>
<tr class="memdesc:gaf5675f82ade15ca38b890f6ea4d035b5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroys the tensor descriptor object.  <a href="group___r_n_n.html#gaf5675f82ade15ca38b890f6ea4d035b5">More...</a><br /></td></tr>
<tr class="separator:gaf5675f82ade15ca38b890f6ea4d035b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga609253972613b2dc6ea2e9d07697f665"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga609253972613b2dc6ea2e9d07697f665">miopenSetRNNDescriptor</a> (miopenRNNDescriptor_t rnnDesc, const int hsize, const int nlayers, <a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a> inMode, <a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a> direction, <a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a> rnnMode, <a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a> biasMode, <a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a> algo, <a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> dataType)</td></tr>
<tr class="memdesc:ga609253972613b2dc6ea2e9d07697f665"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the details of the RNN descriptor.  <a href="group___r_n_n.html#ga609253972613b2dc6ea2e9d07697f665">More...</a><br /></td></tr>
<tr class="separator:ga609253972613b2dc6ea2e9d07697f665"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf02ff9a9c328099753d9244eae95c5d6"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gaf02ff9a9c328099753d9244eae95c5d6">miopenSetRNNDescriptor_V2</a> (miopenRNNDescriptor_t rnnDesc, const int hsize, const int nlayers, miopenDropoutDescriptor_t dropoutDesc, <a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a> inMode, <a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a> direction, <a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a> rnnMode, <a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a> biasMode, <a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a> algo, <a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> dataType)</td></tr>
<tr class="memdesc:gaf02ff9a9c328099753d9244eae95c5d6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the details of the RNN descriptor version 2. This version enables the use of dropout in rnn.  <a href="group___r_n_n.html#gaf02ff9a9c328099753d9244eae95c5d6">More...</a><br /></td></tr>
<tr class="separator:gaf02ff9a9c328099753d9244eae95c5d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadaf0448f9d4ee351183c7e83d2b5f520"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gadaf0448f9d4ee351183c7e83d2b5f520">miopenSetRNNDataSeqTensorDescriptor</a> (miopenSeqTensorDescriptor_t seqTensorDesc, <a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> dataType, <a class="el" href="group___r_n_n.html#ga637e3f078445cce6869966a46e1a486f">miopenRNNBaseLayout_t</a> layout, int maxSequenceLen, int batchSize, int vectorSize, const int *sequenceLenArray, void *paddingMarker)</td></tr>
<tr class="memdesc:gadaf0448f9d4ee351183c7e83d2b5f520"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set shape of RNN seqData tensor.  <a href="group___r_n_n.html#gadaf0448f9d4ee351183c7e83d2b5f520">More...</a><br /></td></tr>
<tr class="separator:gadaf0448f9d4ee351183c7e83d2b5f520"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga90c8af014044546749e8dfd68a074ac3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga90c8af014044546749e8dfd68a074ac3">miopenGetRNNDataSeqTensorDescriptor</a> (miopenSeqTensorDescriptor_t seqTensorDesc, <a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> *dataType, <a class="el" href="group___r_n_n.html#ga637e3f078445cce6869966a46e1a486f">miopenRNNBaseLayout_t</a> *layout, int *maxSequenceLen, int *batchSize, int *vectorSize, int sequenceLenArrayLimit, int *sequenceLenArray, void *paddingMarker)</td></tr>
<tr class="memdesc:ga90c8af014044546749e8dfd68a074ac3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get shape of RNN seqData tensor.  <a href="group___r_n_n.html#ga90c8af014044546749e8dfd68a074ac3">More...</a><br /></td></tr>
<tr class="separator:ga90c8af014044546749e8dfd68a074ac3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad2f8db58662277452612e0b3381123fe"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gad2f8db58662277452612e0b3381123fe">miopenGetRNNWorkspaceSize</a> (miopenHandle_t handle, const miopenRNNDescriptor_t rnnDesc, const int sequenceLen, const miopenTensorDescriptor_t *xDesc, size_t *numBytes)</td></tr>
<tr class="memdesc:gad2f8db58662277452612e0b3381123fe"><td class="mdescLeft">&#160;</td><td class="mdescRight">Query the amount of memory required to execute the RNN layer.  <a href="group___r_n_n.html#gad2f8db58662277452612e0b3381123fe">More...</a><br /></td></tr>
<tr class="separator:gad2f8db58662277452612e0b3381123fe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga59b770093f4ab10d72126436b1d0395a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga59b770093f4ab10d72126436b1d0395a">miopenGetRNNTrainingReserveSize</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int sequenceLen, const miopenTensorDescriptor_t *xDesc, size_t *numBytes)</td></tr>
<tr class="memdesc:ga59b770093f4ab10d72126436b1d0395a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Query the amount of memory required for RNN training.  <a href="group___r_n_n.html#ga59b770093f4ab10d72126436b1d0395a">More...</a><br /></td></tr>
<tr class="separator:ga59b770093f4ab10d72126436b1d0395a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga82cf9678664959b494765e56f06f87c3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga82cf9678664959b494765e56f06f87c3">miopenGetRNNTempSpaceSizes</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, miopenSeqTensorDescriptor_t xDesc, <a class="el" href="group___r_n_n.html#ga9e0d9408f321de068cc30ad5a7de778b">miopenRNNFWDMode_t</a> fwdMode, size_t *workSpaceSize, size_t *reserveSpaceSize)</td></tr>
<tr class="memdesc:ga82cf9678664959b494765e56f06f87c3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Query the amount of additional memory required for this RNN layer execution.  <a href="group___r_n_n.html#ga82cf9678664959b494765e56f06f87c3">More...</a><br /></td></tr>
<tr class="separator:ga82cf9678664959b494765e56f06f87c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2394f4629b6da29bf2145f0e0220810c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga2394f4629b6da29bf2145f0e0220810c">miopenGetRNNParamsSize</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, miopenTensorDescriptor_t xDesc, size_t *numBytes, <a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> dtype)</td></tr>
<tr class="memdesc:ga2394f4629b6da29bf2145f0e0220810c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Query the amount of parameter memory required for RNN training.  <a href="group___r_n_n.html#ga2394f4629b6da29bf2145f0e0220810c">More...</a><br /></td></tr>
<tr class="separator:ga2394f4629b6da29bf2145f0e0220810c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadf75eb328f82b81ddc83d4230b0c54af"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gadf75eb328f82b81ddc83d4230b0c54af">miopenGetRNNParamsDescriptor</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, miopenTensorDescriptor_t xDesc, miopenTensorDescriptor_t wDesc, <a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> dtype)</td></tr>
<tr class="memdesc:gadf75eb328f82b81ddc83d4230b0c54af"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtain a weight tensor descriptor for RNNs.  <a href="group___r_n_n.html#gadf75eb328f82b81ddc83d4230b0c54af">More...</a><br /></td></tr>
<tr class="separator:gadf75eb328f82b81ddc83d4230b0c54af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga97b8a45e7925826423dd5e2795a5f8cd"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga97b8a45e7925826423dd5e2795a5f8cd">miopenGetRNNInputTensorSize</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int seqLen, miopenTensorDescriptor_t *xDesc, size_t *numBytes)</td></tr>
<tr class="memdesc:ga97b8a45e7925826423dd5e2795a5f8cd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtain a the size in bytes of the RNN input tensor.  <a href="group___r_n_n.html#ga97b8a45e7925826423dd5e2795a5f8cd">More...</a><br /></td></tr>
<tr class="separator:ga97b8a45e7925826423dd5e2795a5f8cd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf5d51f866c74ce07a6cc4286fa06200c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gaf5d51f866c74ce07a6cc4286fa06200c">miopenGetRNNHiddenTensorSize</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int seqLen, miopenTensorDescriptor_t *xDesc, size_t *numBytes)</td></tr>
<tr class="memdesc:gaf5d51f866c74ce07a6cc4286fa06200c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Obtain a the size in bytes of the RNN hidden tensor.  <a href="group___r_n_n.html#gaf5d51f866c74ce07a6cc4286fa06200c">More...</a><br /></td></tr>
<tr class="separator:gaf5d51f866c74ce07a6cc4286fa06200c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab082ab70bd71d3d5a248b76bf96def6b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gab082ab70bd71d3d5a248b76bf96def6b">miopenGetRNNLayerParamSize</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int layer, miopenTensorDescriptor_t xDesc, const int paramID, size_t *numBytes)</td></tr>
<tr class="memdesc:gab082ab70bd71d3d5a248b76bf96def6b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the number of bytes of a parameter matrix.  <a href="group___r_n_n.html#gab082ab70bd71d3d5a248b76bf96def6b">More...</a><br /></td></tr>
<tr class="separator:gab082ab70bd71d3d5a248b76bf96def6b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5ed3d73c243de909de9ebf58a1d3d5d8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga5ed3d73c243de909de9ebf58a1d3d5d8">miopenGetRNNLayerBiasSize</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int layer, const int biasID, size_t *numBytes)</td></tr>
<tr class="memdesc:ga5ed3d73c243de909de9ebf58a1d3d5d8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the number of bytes of a bias.  <a href="group___r_n_n.html#ga5ed3d73c243de909de9ebf58a1d3d5d8">More...</a><br /></td></tr>
<tr class="separator:ga5ed3d73c243de909de9ebf58a1d3d5d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gacd0730d483c86d3f9f047658a58f5695"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gacd0730d483c86d3f9f047658a58f5695">miopenGetRNNLayerParam</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int layer, miopenTensorDescriptor_t xDesc, miopenTensorDescriptor_t wDesc, const void *w, const int paramID, miopenTensorDescriptor_t paramDesc, void *layerParam)</td></tr>
<tr class="memdesc:gacd0730d483c86d3f9f047658a58f5695"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets a weight matrix for a specific layer in an RNN stack.  <a href="group___r_n_n.html#gacd0730d483c86d3f9f047658a58f5695">More...</a><br /></td></tr>
<tr class="separator:gacd0730d483c86d3f9f047658a58f5695"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4f27d46b80c043ef254fbc2caf481423"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga4f27d46b80c043ef254fbc2caf481423">miopenGetRNNLayerBias</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int layer, miopenTensorDescriptor_t xDesc, miopenTensorDescriptor_t wDesc, const void *w, const int biasID, miopenTensorDescriptor_t biasDesc, void *layerBias)</td></tr>
<tr class="memdesc:ga4f27d46b80c043ef254fbc2caf481423"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets a bias for a specific layer in an RNN stack.  <a href="group___r_n_n.html#ga4f27d46b80c043ef254fbc2caf481423">More...</a><br /></td></tr>
<tr class="separator:ga4f27d46b80c043ef254fbc2caf481423"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2c445114d21ef806585c4de8fe777b70"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga2c445114d21ef806585c4de8fe777b70">miopenGetRNNLayerParamOffset</a> (miopenRNNDescriptor_t rnnDesc, const int layer, miopenTensorDescriptor_t xDesc, const int paramID, miopenTensorDescriptor_t paramDesc, size_t *layerParamOffset)</td></tr>
<tr class="memdesc:ga2c445114d21ef806585c4de8fe777b70"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets an index offset for a specific weight matrix for a layer in the RNN stack.  <a href="group___r_n_n.html#ga2c445114d21ef806585c4de8fe777b70">More...</a><br /></td></tr>
<tr class="separator:ga2c445114d21ef806585c4de8fe777b70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga24389ba4b784d7211f06b6fe4c94c8d7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga24389ba4b784d7211f06b6fe4c94c8d7">miopenGetRNNLayerBiasOffset</a> (miopenRNNDescriptor_t rnnDesc, const int layer, miopenTensorDescriptor_t xDesc, const int biasID, miopenTensorDescriptor_t biasDesc, size_t *layerBiasOffset)</td></tr>
<tr class="memdesc:ga24389ba4b784d7211f06b6fe4c94c8d7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets a bias index offset for a specific layer in an RNN stack.  <a href="group___r_n_n.html#ga24389ba4b784d7211f06b6fe4c94c8d7">More...</a><br /></td></tr>
<tr class="separator:ga24389ba4b784d7211f06b6fe4c94c8d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa13b97d4ebe9960126140e7838701e13"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gaa13b97d4ebe9960126140e7838701e13">miopenSetRNNLayerParam</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int layer, miopenTensorDescriptor_t xDesc, miopenTensorDescriptor_t wDesc, void *w, const int paramID, miopenTensorDescriptor_t paramDesc, const void *layerParam)</td></tr>
<tr class="memdesc:gaa13b97d4ebe9960126140e7838701e13"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets a weight matrix for a specific layer in an RNN stack.  <a href="group___r_n_n.html#gaa13b97d4ebe9960126140e7838701e13">More...</a><br /></td></tr>
<tr class="separator:gaa13b97d4ebe9960126140e7838701e13"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1991ee70fba68f8de643c1a4aa183bf7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga1991ee70fba68f8de643c1a4aa183bf7">miopenSetRNNLayerBias</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int layer, miopenTensorDescriptor_t xDesc, miopenTensorDescriptor_t wDesc, void *w, const int biasID, miopenTensorDescriptor_t biasDesc, const void *layerBias)</td></tr>
<tr class="memdesc:ga1991ee70fba68f8de643c1a4aa183bf7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets a bias for a specific layer in an RNN stack.  <a href="group___r_n_n.html#ga1991ee70fba68f8de643c1a4aa183bf7">More...</a><br /></td></tr>
<tr class="separator:ga1991ee70fba68f8de643c1a4aa183bf7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf9f746d7c62bfbf62ff8663e54360771"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gaf9f746d7c62bfbf62ff8663e54360771">miopenSetRNNPaddingMode</a> (miopenRNNDescriptor_t rnnDesc, <a class="el" href="group___r_n_n.html#gaeb0b6dbeefb776e9b663c66a247a7121">miopenRNNPaddingMode_t</a> paddingMode)</td></tr>
<tr class="memdesc:gaf9f746d7c62bfbf62ff8663e54360771"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets a bias for a specific layer in an RNN stack.  <a href="group___r_n_n.html#gaf9f746d7c62bfbf62ff8663e54360771">More...</a><br /></td></tr>
<tr class="separator:gaf9f746d7c62bfbf62ff8663e54360771"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga86fc04d775ab501c0ab829703b2cf738"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga86fc04d775ab501c0ab829703b2cf738">miopenGetRNNPaddingMode</a> (miopenRNNDescriptor_t rnnDesc, <a class="el" href="group___r_n_n.html#gaeb0b6dbeefb776e9b663c66a247a7121">miopenRNNPaddingMode_t</a> *paddingMode)</td></tr>
<tr class="memdesc:ga86fc04d775ab501c0ab829703b2cf738"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function retrieves the RNN padding mode from the RNN descriptor.  <a href="group___r_n_n.html#ga86fc04d775ab501c0ab829703b2cf738">More...</a><br /></td></tr>
<tr class="separator:ga86fc04d775ab501c0ab829703b2cf738"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8d5b72681258d9cd7f50ba03ab6215e5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga8d5b72681258d9cd7f50ba03ab6215e5">miopenRNNForward</a> (miopenHandle_t handle, const miopenRNNDescriptor_t rnnDesc, <a class="el" href="group___r_n_n.html#ga9e0d9408f321de068cc30ad5a7de778b">miopenRNNFWDMode_t</a> fwdMode, const miopenSeqTensorDescriptor_t xDesc, const void *x, const miopenTensorDescriptor_t hDesc, const void *hx, void *hy, const miopenTensorDescriptor_t cDesc, const void *cx, void *cy, const miopenSeqTensorDescriptor_t yDesc, void *y, const void *w, size_t weightSpaceSize, void *workSpace, size_t workSpaceNumBytes, void *reserveSpace, size_t reserveSpaceNumBytes)</td></tr>
<tr class="memdesc:ga8d5b72681258d9cd7f50ba03ab6215e5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute forward training for recurrent layer.  <a href="group___r_n_n.html#ga8d5b72681258d9cd7f50ba03ab6215e5">More...</a><br /></td></tr>
<tr class="separator:ga8d5b72681258d9cd7f50ba03ab6215e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga44ac8be6fceea4aa1e755958960be862"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga44ac8be6fceea4aa1e755958960be862">miopenRNNBackwardSeqData</a> (miopenHandle_t handle, const miopenRNNDescriptor_t rnnDesc, const miopenSeqTensorDescriptor_t yDesc, const void *y, const void *dy, const miopenTensorDescriptor_t hDesc, const void *hx, const void *dhy, void *dhx, const miopenTensorDescriptor_t cDesc, const void *cx, const void *dcy, void *dcx, const miopenSeqTensorDescriptor_t xDesc, void *dx, const void *w, size_t weightSpaceSize, void *workSpace, size_t workSpaceNumBytes, void *reserveSpace, size_t reserveSpaceNumBytes)</td></tr>
<tr class="memdesc:ga44ac8be6fceea4aa1e755958960be862"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute backward data for recurrent layer.  <a href="group___r_n_n.html#ga44ac8be6fceea4aa1e755958960be862">More...</a><br /></td></tr>
<tr class="separator:ga44ac8be6fceea4aa1e755958960be862"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1ff33e5279bfca3ed08d59bfa8069a9d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga1ff33e5279bfca3ed08d59bfa8069a9d">miopenRNNBackwardWeightsSeqTensor</a> (miopenHandle_t handle, const miopenRNNDescriptor_t rnnDesc, const miopenSeqTensorDescriptor_t xDesc, const void *x, const miopenTensorDescriptor_t hDesc, const void *hx, const miopenSeqTensorDescriptor_t yDesc, const void *y, void *dw, size_t weightSpaceSize, void *workSpace, size_t workSpaceNumBytes, const void *reserveSpace, size_t reserveSpaceNumBytes)</td></tr>
<tr class="memdesc:ga1ff33e5279bfca3ed08d59bfa8069a9d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute backward weights for recurrent layer.  <a href="group___r_n_n.html#ga1ff33e5279bfca3ed08d59bfa8069a9d">More...</a><br /></td></tr>
<tr class="separator:ga1ff33e5279bfca3ed08d59bfa8069a9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae7844191464b02e0343af135904413ab"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gae7844191464b02e0343af135904413ab">miopenRNNForwardTraining</a> (miopenHandle_t handle, const miopenRNNDescriptor_t rnnDesc, const int sequenceLen, const miopenTensorDescriptor_t *xDesc, const void *x, const miopenTensorDescriptor_t hxDesc, const void *hx, const miopenTensorDescriptor_t cxDesc, const void *cx, const miopenTensorDescriptor_t wDesc, const void *w, const miopenTensorDescriptor_t *yDesc, void *y, const miopenTensorDescriptor_t hyDesc, void *hy, const miopenTensorDescriptor_t cyDesc, void *cy, void *workSpace, size_t workSpaceNumBytes, void *reserveSpace, size_t reserveSpaceNumBytes)</td></tr>
<tr class="memdesc:gae7844191464b02e0343af135904413ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute forward training for recurrent layer.  <a href="group___r_n_n.html#gae7844191464b02e0343af135904413ab">More...</a><br /></td></tr>
<tr class="separator:gae7844191464b02e0343af135904413ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6ac03fa91d038feb1206b4f8a770af97"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga6ac03fa91d038feb1206b4f8a770af97">miopenRNNBackwardData</a> (miopenHandle_t handle, const miopenRNNDescriptor_t rnnDesc, const int sequenceLen, const miopenTensorDescriptor_t *yDesc, const void *y, const miopenTensorDescriptor_t *dyDesc, const void *dy, const miopenTensorDescriptor_t dhyDesc, const void *dhy, const miopenTensorDescriptor_t dcyDesc, const void *dcy, const miopenTensorDescriptor_t wDesc, const void *w, const miopenTensorDescriptor_t hxDesc, const void *hx, const miopenTensorDescriptor_t cxDesc, const void *cx, const miopenTensorDescriptor_t *dxDesc, void *dx, const miopenTensorDescriptor_t dhxDesc, void *dhx, const miopenTensorDescriptor_t dcxDesc, void *dcx, void *workSpace, size_t workSpaceNumBytes, void *reserveSpace, size_t reserveSpaceNumBytes)</td></tr>
<tr class="memdesc:ga6ac03fa91d038feb1206b4f8a770af97"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute backward data for recurrent layer.  <a href="group___r_n_n.html#ga6ac03fa91d038feb1206b4f8a770af97">More...</a><br /></td></tr>
<tr class="separator:ga6ac03fa91d038feb1206b4f8a770af97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga55040b58e6820d21f58957d356715739"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#ga55040b58e6820d21f58957d356715739">miopenRNNBackwardWeights</a> (miopenHandle_t handle, const miopenRNNDescriptor_t rnnDesc, const int sequenceLen, const miopenTensorDescriptor_t *xDesc, const void *x, const miopenTensorDescriptor_t hxDesc, const void *hx, const miopenTensorDescriptor_t *yDesc, const void *y, const miopenTensorDescriptor_t dwDesc, void *dw, void *workSpace, size_t workSpaceNumBytes, const void *reserveSpace, size_t reserveSpaceNumBytes)</td></tr>
<tr class="memdesc:ga55040b58e6820d21f58957d356715739"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute backward weights for recurrent layer.  <a href="group___r_n_n.html#ga55040b58e6820d21f58957d356715739">More...</a><br /></td></tr>
<tr class="separator:ga55040b58e6820d21f58957d356715739"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafd8f2c43d92a7baf7de2e431bbcf7199"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___r_n_n.html#gafd8f2c43d92a7baf7de2e431bbcf7199">miopenRNNForwardInference</a> (miopenHandle_t handle, miopenRNNDescriptor_t rnnDesc, const int sequenceLen, const miopenTensorDescriptor_t *xDesc, const void *x, const miopenTensorDescriptor_t hxDesc, const void *hx, const miopenTensorDescriptor_t cxDesc, const void *cx, const miopenTensorDescriptor_t wDesc, const void *w, const miopenTensorDescriptor_t *yDesc, void *y, const miopenTensorDescriptor_t hyDesc, void *hy, const miopenTensorDescriptor_t cyDesc, void *cy, void *workSpace, size_t workSpaceNumBytes)</td></tr>
<tr class="memdesc:gafd8f2c43d92a7baf7de2e431bbcf7199"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute forward inference for RNN layer.  <a href="group___r_n_n.html#gafd8f2c43d92a7baf7de2e431bbcf7199">More...</a><br /></td></tr>
<tr class="separator:gafd8f2c43d92a7baf7de2e431bbcf7199"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="ga6bca6bf2c239cb387d99a07cb6b331c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6bca6bf2c239cb387d99a07cb6b331c4">&#9670;&nbsp;</a></span>miopenRNNAlgo_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Recurrent Neural Network algorithm mode </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga6bca6bf2c239cb387d99a07cb6b331c4aee4782e7cebfb009314cdd6c695a5b90"></a>miopenRNNdefault&#160;</td><td class="fielddoc"><p>Use dedicated gate-operation kernel for LSTM and fundamental algorithm for vanilla RNN &amp; GRU </p>
</td></tr>
<tr><td class="fieldname"><a id="gga6bca6bf2c239cb387d99a07cb6b331c4a2dfd71a22376cd8b11bd1a1b4fe46996"></a>miopenRNNfundamental&#160;</td><td class="fielddoc"><p>Function by basic tesnsor operations, supported for vanilla RNN, LSTM, GRU </p>
</td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a285">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga637e3f078445cce6869966a46e1a486f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga637e3f078445cce6869966a46e1a486f">&#9670;&nbsp;</a></span>miopenRNNBaseLayout_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#ga637e3f078445cce6869966a46e1a486f">miopenRNNBaseLayout_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Data layouts for RNN operations </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga637e3f078445cce6869966a46e1a486fae9bb9aaef77070d408758f4d2dbef44d"></a>miopenRNNDataUnknownLayout&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="gga637e3f078445cce6869966a46e1a486fa956d8d35f87c4aa06a4f9d5561aef5f1"></a>miopenRNNDataSeqMajorNotPadded&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="gga637e3f078445cce6869966a46e1a486fa04fbe3dee060a5d78eb007028468134f"></a>miopenRNNDataSeqMajorPadded&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="gga637e3f078445cce6869966a46e1a486fad5db52f1c42231b13de635892872c931"></a>miopenRNNDataBatchMajorPadded&#160;</td><td class="fielddoc"></td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a304">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga47b037e570937a567de38e8898a99f37"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga47b037e570937a567de38e8898a99f37">&#9670;&nbsp;</a></span>miopenRNNBiasMode_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Recurrent Neural Network add on bias </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga47b037e570937a567de38e8898a99f37a2eb8172730ba33866564865fe4e2d7ea"></a>miopenRNNNoBias&#160;</td><td class="fielddoc"><p>No Biases will be applied to GEMM operations </p>
</td></tr>
<tr><td class="fieldname"><a id="gga47b037e570937a567de38e8898a99f37a14fd5be6ddb03ef2d81d27ff8a868d10"></a>miopenRNNwithBias&#160;</td><td class="fielddoc"><p>Biases will be applied to GEMM operations </p>
</td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a291">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga3c7adae8941033d266f1d5e029504c38"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3c7adae8941033d266f1d5e029504c38">&#9670;&nbsp;</a></span>miopenRNNDirectionMode_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Recurrent Neural Network bi-directional behavior </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga3c7adae8941033d266f1d5e029504c38a78752802fd2c7248fd4fdddbf613264b"></a>miopenRNNunidirection&#160;</td><td class="fielddoc"><p>Forward in time only. </p>
</td></tr>
<tr><td class="fieldname"><a id="gga3c7adae8941033d266f1d5e029504c38a2f0f99690655d0df5ca16bd5011908ea"></a>miopenRNNbidirection&#160;</td><td class="fielddoc"><p>Forward and backwards in time. </p>
</td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a288">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga9e0d9408f321de068cc30ad5a7de778b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga9e0d9408f321de068cc30ad5a7de778b">&#9670;&nbsp;</a></span>miopenRNNFWDMode_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#ga9e0d9408f321de068cc30ad5a7de778b">miopenRNNFWDMode_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Recurrent Neural Network Training/Inference mode </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga9e0d9408f321de068cc30ad5a7de778ba2a424459293f8f7a74ab45b70a902f4e"></a>miopenRNNTraining&#160;</td><td class="fielddoc"><p>FWD, BWD, WRW </p>
</td></tr>
<tr><td class="fieldname"><a id="gga9e0d9408f321de068cc30ad5a7de778ba2e5ed4c109920976110cdc7c7fd4cefc"></a>miopenRNNInference&#160;</td><td class="fielddoc"><p>Only FWD-inference no back-propagation </p>
</td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a299">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gac7f800028b5634cb08aa191fa6ee0d2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac7f800028b5634cb08aa191fa6ee0d2a">&#9670;&nbsp;</a></span>miopenRNNGEMMalgoMode_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#gac7f800028b5634cb08aa191fa6ee0d2a">miopenRNNGEMMalgoMode_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Recurrent Neural Network add on bias </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="ggac7f800028b5634cb08aa191fa6ee0d2aa5803419df2c12a2ea02b7560a54ebee7"></a>miopenRNNAlgoGEMM&#160;</td><td class="fielddoc"></td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a293">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga11808e1b616d9b9d7e6c701986783af7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga11808e1b616d9b9d7e6c701986783af7">&#9670;&nbsp;</a></span>miopenRNNInputMode_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Recurrent Neural Network layer initial input mode </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga11808e1b616d9b9d7e6c701986783af7a168f261ee3dc35ea3fe636c644610c2f"></a>miopenRNNlinear&#160;</td><td class="fielddoc"><p>Matrix multiplication at the input of the first layer </p>
</td></tr>
<tr><td class="fieldname"><a id="gga11808e1b616d9b9d7e6c701986783af7a99c1caff2a69fb37d964fb3692c989da"></a>miopenRNNskip&#160;</td><td class="fielddoc"><p>No operation is performed at the input of the first layer. </p>
</td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a282">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga016f266507f199def908fe39c43d7877"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga016f266507f199def908fe39c43d7877">&#9670;&nbsp;</a></span>miopenRNNMode_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>RNN mode selection for rnn layer preference </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="gga016f266507f199def908fe39c43d7877af714eb36c96ca365b643e7e8417c10cc"></a>miopenRNNRELU&#160;</td><td class="fielddoc"><p>RNN with ReLU activation </p>
</td></tr>
<tr><td class="fieldname"><a id="gga016f266507f199def908fe39c43d7877a1d43e2e3151aa1266cc10e8623c0a32b"></a>miopenRNNTANH&#160;</td><td class="fielddoc"><p>RNN with tanh activation </p>
</td></tr>
<tr><td class="fieldname"><a id="gga016f266507f199def908fe39c43d7877a97804b8e078f16b327e50e5554df970c"></a>miopenLSTM&#160;</td><td class="fielddoc"><p>LSTM </p>
</td></tr>
<tr><td class="fieldname"><a id="gga016f266507f199def908fe39c43d7877aa13bc340d91e98e610e92b75e5928a66"></a>miopenGRU&#160;</td><td class="fielddoc"><p>GRU </p>
</td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a279">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gaeb0b6dbeefb776e9b663c66a247a7121"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaeb0b6dbeefb776e9b663c66a247a7121">&#9670;&nbsp;</a></span>miopenRNNPaddingMode_t</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___r_n_n.html#gaeb0b6dbeefb776e9b663c66a247a7121">miopenRNNPaddingMode_t</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Recurrent Neural Network input/output data padding mode </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="ggaeb0b6dbeefb776e9b663c66a247a7121a280a03179097c1c96d3b26f4f25543e2"></a>miopenRNNIONotPadded&#160;</td><td class="fielddoc"><p>Not padded data at RNN input/output </p>
</td></tr>
<tr><td class="fieldname"><a id="ggaeb0b6dbeefb776e9b663c66a247a7121a0d1f9de9cb101771b9bb572ddfa2f2ef"></a>miopenRNNIOWithPadding&#160;</td><td class="fielddoc"><p>Padded data at RNN input/output </p>
</td></tr>
</table>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a296">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga781cb4cafc3e631e189a0ec014a2729f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga781cb4cafc3e631e189a0ec014a2729f">&#9670;&nbsp;</a></span>MIOPEN_DECLARE_OBJECT()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">MIOPEN_DECLARE_OBJECT </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Creates the miopenRNNDescriptor_t type. </p>

</div>
</div>
<a id="gab6af15d94b2e0932873142d55aa239b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab6af15d94b2e0932873142d55aa239b4">&#9670;&nbsp;</a></span>miopenCreateRNNDescriptor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenCreateRNNDescriptor </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t *&#160;</td>
          <td class="paramname"><em>rnnDesc</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a RNN layer Descriptor. </p>
<p>API for creating an uninitialized RNN layer descriptor. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>Pointer to a tensor descriptor type </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a305">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gaf5675f82ade15ca38b890f6ea4d035b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf5675f82ade15ca38b890f6ea4d035b5">&#9670;&nbsp;</a></span>miopenDestroyRNNDescriptor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenDestroyRNNDescriptor </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destroys the tensor descriptor object. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN tensor descriptor type (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a308">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga90c8af014044546749e8dfd68a074ac3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga90c8af014044546749e8dfd68a074ac3">&#9670;&nbsp;</a></span>miopenGetRNNDataSeqTensorDescriptor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNDataSeqTensorDescriptor </td>
          <td>(</td>
          <td class="paramtype">miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>seqTensorDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> *&#160;</td>
          <td class="paramname"><em>dataType</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga637e3f078445cce6869966a46e1a486f">miopenRNNBaseLayout_t</a> *&#160;</td>
          <td class="paramname"><em>layout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>maxSequenceLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>batchSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>vectorSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sequenceLenArrayLimit</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>sequenceLenArray</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>paddingMarker</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Get shape of RNN seqData tensor. </p>
<p>Interface for setting tensor shape to be used as RNN input data</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">seqTensorDesc</td><td>Tensor descriptor (input) </td></tr>
    <tr><td class="paramname">dataType</td><td>MIOpen datatype (output) </td></tr>
    <tr><td class="paramname">layout</td><td>One of the main supported layouts for RNN data(output) </td></tr>
    <tr><td class="paramname">maxSequenceLen</td><td>Sequence length limit within this SeqTensor(output) </td></tr>
    <tr><td class="paramname">batchSize</td><td>Number of sequences within this SeqTensor (output) </td></tr>
    <tr><td class="paramname">vectorSize</td><td>Vector size (output) </td></tr>
    <tr><td class="paramname">sequenceLenArrayLimit</td><td>Limit for number of elements that can be returned to user by sequenceLenArray (input) </td></tr>
    <tr><td class="paramname">sequenceLenArray</td><td>Array containing the length of each sequence in the SeqTensor. This is allowed to be a NULL pointer if sequenceLenArrayLimit is 0 (output) </td></tr>
    <tr><td class="paramname">paddingMarker</td><td>Not used, should be NULL (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a312">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga6ac11f7ee823327d80e1b0ebc6774b3f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6ac11f7ee823327d80e1b0ebc6774b3f">&#9670;&nbsp;</a></span>miopenGetRNNDescriptor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNDescriptor </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a> *&#160;</td>
          <td class="paramname"><em>rnnMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a> *&#160;</td>
          <td class="paramname"><em>algoMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a> *&#160;</td>
          <td class="paramname"><em>inputMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a> *&#160;</td>
          <td class="paramname"><em>dirMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a> *&#160;</td>
          <td class="paramname"><em>biasMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>hiddenSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>layer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Retrieves a RNN layer descriptor's details. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor (input) </td></tr>
    <tr><td class="paramname">rnnMode</td><td>RNN mode (output) </td></tr>
    <tr><td class="paramname">algoMode</td><td>RNN algorithm mode (output) </td></tr>
    <tr><td class="paramname">inputMode</td><td>RNN data input mode (output) </td></tr>
    <tr><td class="paramname">dirMode</td><td>Uni or bi direction mode (output) </td></tr>
    <tr><td class="paramname">biasMode</td><td>Bias used (output) </td></tr>
    <tr><td class="paramname">hiddenSize</td><td>Size of hidden state (output) </td></tr>
    <tr><td class="paramname">layer</td><td>Number of stacked layers (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a306">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga102a6710811b4662eee1c3f2858b3498"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga102a6710811b4662eee1c3f2858b3498">&#9670;&nbsp;</a></span>miopenGetRNNDescriptor_V2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNDescriptor_V2 </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>hiddenSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenDropoutDescriptor_t *&#160;</td>
          <td class="paramname"><em>dropoutDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a> *&#160;</td>
          <td class="paramname"><em>inputMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a> *&#160;</td>
          <td class="paramname"><em>dirMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a> *&#160;</td>
          <td class="paramname"><em>rnnMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a> *&#160;</td>
          <td class="paramname"><em>biasMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a> *&#160;</td>
          <td class="paramname"><em>algoMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a> *&#160;</td>
          <td class="paramname"><em>dataType</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Retrieves a RNN layer descriptor's details version 2. This version enables retrieving information of the dropout descriptor of the rnn descriptor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor (input) </td></tr>
    <tr><td class="paramname">hiddenSize</td><td>Size of hidden state (output) </td></tr>
    <tr><td class="paramname">layer</td><td>Number of stacked layers (output) </td></tr>
    <tr><td class="paramname">dropoutDesc</td><td>Pre-configured dropout descriptor for dropout layer in between RNN layers (output) </td></tr>
    <tr><td class="paramname">inputMode</td><td>RNN data input mode (output) </td></tr>
    <tr><td class="paramname">dirMode</td><td>Uni or bi direction mode (output) </td></tr>
    <tr><td class="paramname">rnnMode</td><td>RNN mode (output) </td></tr>
    <tr><td class="paramname">biasMode</td><td>Bias used (output) </td></tr>
    <tr><td class="paramname">algoMode</td><td>RNN algorithm mode (output) </td></tr>
    <tr><td class="paramname">dataType</td><td>Data type of RNN (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a307">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gaf5d51f866c74ce07a6cc4286fa06200c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf5d51f866c74ce07a6cc4286fa06200c">&#9670;&nbsp;</a></span>miopenGetRNNHiddenTensorSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNHiddenTensorSize </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>seqLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>numBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Obtain a the size in bytes of the RNN hidden tensor. </p>
<p>This function determines the size in bytes of the allocation needed for the hidden tensor over all layers</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>Fully populated RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">seqLen</td><td>Number of iteration unrolls (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>An array of previously populated tensor descriptors (input) </td></tr>
    <tr><td class="paramname">numBytes</td><td>Number of bytes required for input tensor (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a319">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga97b8a45e7925826423dd5e2795a5f8cd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga97b8a45e7925826423dd5e2795a5f8cd">&#9670;&nbsp;</a></span>miopenGetRNNInputTensorSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNInputTensorSize </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>seqLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>numBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Obtain a the size in bytes of the RNN input tensor. </p>
<p>This function determines the size in bytes of the allocation needed for the input data tensor for an RNN layer. The number of bytes is derived from the array of tensor descriptors.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>Fully populated RNN layer descriptor (input) </td></tr>
    <tr><td class="paramname">seqLen</td><td>Number of iteration unrolls (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>An array of tensor descriptors. These are the input descriptors to each time step. The first dimension of each descriptor is the batch size and may decrease from element n to element n+1 and not increase in size. The second dimension is the same for all descriptors in the array and is the input vector length. (input) </td></tr>
    <tr><td class="paramname">numBytes</td><td>Number of bytes required for input tensor (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a318">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga4f27d46b80c043ef254fbc2caf481423"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4f27d46b80c043ef254fbc2caf481423">&#9670;&nbsp;</a></span>miopenGetRNNLayerBias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNLayerBias </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>wDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>biasID</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>biasDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>layerBias</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets a bias for a specific layer in an RNN stack. </p>
<p>This function retrieves the bias data for a specific layer and bias ID and copies the data into previously allocated device memory.</p>
<p>For RNN vanilla miopenRNNRELU and miopenRNNTANH, biasID == 0 retrieves the bias associated with the in input GEMM, while biasID == 1 retrieves the bias associated with the hidden state GEMM.</p>
<p>For miopenLSTM biasID 0 to 3 refer to the biases associated with the input GEMM, 4-7 are associated with biases associated with the hidden state GEMM.</p>
<ul>
<li>biasID 0 and 4 are for the input gate.</li>
<li>biasID 1 and 5 are for the forget gate.</li>
<li>biasID 2 and 6 are for the output gate.</li>
<li>biasID 3 and 7 are for the new memory gate.</li>
</ul>
<p>For miopenGRU biasID 0 to 2 refer to the biases associated with the input GEMM, while 3 through 5 are associated with the hidden state GEMM.</p>
<ul>
<li>biasID 0 and 3 are for the update gate.</li>
<li>biasID 1 and 4 are for the reset gate.</li>
<li>biasID 2 and 5 are for the new memory gate.</li>
</ul>
<p>For bi-directional RNNs the backwards in time direction is numbered as the layer directly after the forward in time direction.</p>
<p>The output argument biasDesc is a previously created tensor descriptor that is populated to describe the memory layout of the bias. It is full packed and is used when calling to <a class="el" href="group___r_n_n.html#ga1991ee70fba68f8de643c1a4aa183bf7" title="Sets a bias for a specific layer in an RNN stack.">miopenSetRNNLayerBias()</a></p>
<p>The argument layerBias should either be nullptr, or have device memory allocated to allow copying of the entire layer bias into it. If layerBias is nullptr then only the biasDesc is populated and returned. The size in bytes of the layer bias can be determined by using <a class="el" href="group___r_n_n.html#ga5ed3d73c243de909de9ebf58a1d3d5d8" title="Gets the number of bytes of a bias.">miopenGetRNNLayerBiasSize()</a>.</p>
<p>Note: When inputSkip mode is selected there is no input layer matrix operation, and therefore no associated memory. In this case <a class="el" href="group___r_n_n.html#ga4f27d46b80c043ef254fbc2caf481423" title="Gets a bias for a specific layer in an RNN stack.">miopenGetRNNLayerBias()</a> will return a error status miopenStatusBadParm for input biasID associated with the input GEMM.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">layer</td><td>The layer number in the RNN stack (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A tensor descriptor to input (input) </td></tr>
    <tr><td class="paramname">wDesc</td><td>A tensor descriptor to the parameter tensor (input) </td></tr>
    <tr><td class="paramname">w</td><td>Pointer to memory containing parameter tensor (input) </td></tr>
    <tr><td class="paramname">biasID</td><td>ID of the internal parameter tensor (input) </td></tr>
    <tr><td class="paramname">biasDesc</td><td>Descriptor of the parameter tensor (output) </td></tr>
    <tr><td class="paramname">layerBias</td><td>Pointer to the memory location of the bias tensor (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a323">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga24389ba4b784d7211f06b6fe4c94c8d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga24389ba4b784d7211f06b6fe4c94c8d7">&#9670;&nbsp;</a></span>miopenGetRNNLayerBiasOffset()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNLayerBiasOffset </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>biasID</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>biasDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>layerBiasOffset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets a bias index offset for a specific layer in an RNN stack. </p>
<p>This function retrieves the bias index offset for a specific layer and bias ID.</p>
<p>For RNN vanilla miopenRNNRELU and miopenRNNTANH, biasID == 0 retrieves the bias associated with the in input GEMM, while biasID == 1 retrieves the weight matrix associated with the hidden state GEMM.</p>
<p>For miopenLSTM biasID 0 to 3 refer to the bias offset associated with the input GEMM, 4-7 are the bias offsets associated with the hidden state GEMM.</p>
<ul>
<li>biasID 0 and 4 are for the input gate.</li>
<li>biasID 1 and 5 are for the forget gate.</li>
<li>biasID 2 and 6 are for the output gate.</li>
<li>biasID 3 and 7 are for the new memory gate.</li>
</ul>
<p>For miopenGRU biasID 0 to 2 refer to the biases associated with the input GEMM, while 3 through 5 are associated with the hidden state GEMM.</p>
<ul>
<li>biasID 0 and 3 are for the update gate.</li>
<li>biasID 1 and 4 are for the reset gate.</li>
<li>biasID 2 and 5 are for the new memory gate.</li>
</ul>
<p>For bi-directional RNNs the backwards in time direction is numbered as the layer directly after the forward in time direction.</p>
<p>The output argument biasDesc is a previously created tensor descriptor that is populated to describe the memory layout of the bias. It is full packed and is used when calling to <a class="el" href="group___r_n_n.html#ga1991ee70fba68f8de643c1a4aa183bf7" title="Sets a bias for a specific layer in an RNN stack.">miopenSetRNNLayerBias()</a></p>
<p>The argument layerBiasOffset should either be nullptr, or point to an output address. If layerBias is nullptr then only the biasDesc is populated and returned.</p>
<p>Note: When inputSkip mode is selected there is no input layer matrix operation, and therefore no associated memory. In this case <a class="el" href="group___r_n_n.html#ga24389ba4b784d7211f06b6fe4c94c8d7" title="Gets a bias index offset for a specific layer in an RNN stack.">miopenGetRNNLayerBiasOffset()</a> will return a error status miopenStatusBadParm for input biasID associated with the input GEMM.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">layer</td><td>The layer number in the RNN stack (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A tensor descriptor to input (input) </td></tr>
    <tr><td class="paramname">biasID</td><td>ID of the internal parameter tensor (input) </td></tr>
    <tr><td class="paramname">biasDesc</td><td>Descriptor of the parameter tensor (output) </td></tr>
    <tr><td class="paramname">layerBiasOffset</td><td>Pointer to the memory location of the bias tensor (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a325">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga5ed3d73c243de909de9ebf58a1d3d5d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga5ed3d73c243de909de9ebf58a1d3d5d8">&#9670;&nbsp;</a></span>miopenGetRNNLayerBiasSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNLayerBiasSize </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>biasID</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>numBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the number of bytes of a bias. </p>
<p>For RNN vanilla miopenRNNRELU and miopenRNNTANH, biasID == 0 retrieves the weight matrix associated with the in input GEMM, while biasID == 1 retrieves the bias associated with the hidden state GEMM.</p>
<p>For miopenLSTM biasID 0 to 3 refer to the biases associated with the input GEMM, 4-7 are associated with biases associated with the hidden state GEMM.</p>
<ul>
<li>biasID 0 and 4 are for the input gate.</li>
<li>biasID 1 and 5 are for the forget gate.</li>
<li>biasID 2 and 6 are for the output gate.</li>
<li>biasID 3 and 7 are for the new memory gate.</li>
</ul>
<p>For miopenGRU biasID 0 to 2 refer to the biases associated with the input GEMM, while 3 through 5 are associated with the hidden state GEMM.</p>
<ul>
<li>biasID 0 and 3 are for the update gate.</li>
<li>biasID 1 and 4 are for the reset gate.</li>
<li>biasID 2 and 5 are for the new memory gate.</li>
</ul>
<p>For bi-directional RNNs the backwards in time direction is numbered as the layer directly after the forward in time direction.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">layer</td><td>The layer number in the RNN stack (input) </td></tr>
    <tr><td class="paramname">biasID</td><td>ID of the internal parameter tensor (input) </td></tr>
    <tr><td class="paramname">numBytes</td><td>The number of bytes of the layer's bias (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a321">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gacd0730d483c86d3f9f047658a58f5695"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gacd0730d483c86d3f9f047658a58f5695">&#9670;&nbsp;</a></span>miopenGetRNNLayerParam()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNLayerParam </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>wDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>paramID</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>paramDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>layerParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets a weight matrix for a specific layer in an RNN stack. </p>
<p>This function retrieves the weight matrix data for a specific layer and parameter ID and copies the data into previously allocated device memory.</p>
<p>For RNN vanilla miopenRNNRELU and miopenRNNTANH, paramID == 0 retrieves the weight matrix associated with the in input GEMM, while paramID == 1 retrieves the weight matrix associated with the hidden state GEMM.</p>
<p>For miopenLSTM paramID 0 to 3 refer to the weight matrices associated with the input GEMM, 4-7 are associated with matrices associated with the hidden state GEMM.</p>
<ul>
<li>paramID 0 and 4 are for the input gate.</li>
<li>paramID 1 and 5 are for the forget gate.</li>
<li>paramID 2 and 6 are for the output gate.</li>
<li>paramID 3 and 7 are for the new memory gate.</li>
</ul>
<p>For miopenGRU paramID 0 to 2 refer to the weight matrix offset associated with the input GEMM, while 3 through 5 are associated with the hidden state GEMM.</p>
<ul>
<li>paramID 0 and 3 are for the update gate.</li>
<li>paramID 1 and 4 are for the reset gate.</li>
<li>paramID 2 and 5 are for the new memory gate.</li>
</ul>
<p>For bi-directional RNNs the backwards in time direction is numbered as the layer directly after the forward in time direction.</p>
<p>The output argument paramDesc is a previously created tensor descriptor that is populated to describe the memory layout of the parameter matrix. It is full packed and is used when calling to <a class="el" href="group___r_n_n.html#gaa13b97d4ebe9960126140e7838701e13" title="Sets a weight matrix for a specific layer in an RNN stack.">miopenSetRNNLayerParam()</a></p>
<p>The argument layerParam should either be nullptr, or have device memory allocated to allow copying of the entire layer parameter matrix into it. If layerParam is nullptr then only the paramDesc is populated and returned. The size in bytes of the layer parameter matrix can be determined by using <a class="el" href="group___r_n_n.html#gab082ab70bd71d3d5a248b76bf96def6b" title="Gets the number of bytes of a parameter matrix.">miopenGetRNNLayerParamSize()</a>.</p>
<p>Note: When inputSkip mode is selected there is no input layer matrix operation, and therefore no associated memory. In this case <a class="el" href="group___r_n_n.html#gacd0730d483c86d3f9f047658a58f5695" title="Gets a weight matrix for a specific layer in an RNN stack.">miopenGetRNNLayerParam()</a> will return a error status miopenStatusBadParm for input paramID associated with the input GEMM.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">layer</td><td>The layer number in the RNN stack (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A tensor descriptor to input (input) </td></tr>
    <tr><td class="paramname">wDesc</td><td>A tensor descriptor to the parameter tensor (input) </td></tr>
    <tr><td class="paramname">w</td><td>Pointer to memory containing parameter tensor (input) </td></tr>
    <tr><td class="paramname">paramID</td><td>ID of the internal parameter tensor (input) </td></tr>
    <tr><td class="paramname">paramDesc</td><td>Tensor descriptor for the fully packed output parameter tensor (output) </td></tr>
    <tr><td class="paramname">layerParam</td><td>Pointer to the memory location of the parameter tensor (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a322">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga2c445114d21ef806585c4de8fe777b70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2c445114d21ef806585c4de8fe777b70">&#9670;&nbsp;</a></span>miopenGetRNNLayerParamOffset()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNLayerParamOffset </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>paramID</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>paramDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>layerParamOffset</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets an index offset for a specific weight matrix for a layer in the RNN stack. </p>
<p>This function retrieves the index offset for a weight matrix in a layer.</p>
<p>For RNN vanilla miopenRNNRELU and miopenRNNTANH, paramID == 0 retrieves the weight matrix offset associated with the in input GEMM, while paramID == 1 retrieves the weight matrix offset associated with the hidden state GEMM.</p>
<p>For miopenLSTM paramID 0 to 3 refer to the weight matrix offsets associated with the input GEMM, 4-7 are associated with matrix offset associated with the hidden state GEMM.</p>
<ul>
<li>paramID 0 and 4 are for the input gate.</li>
<li>paramID 1 and 5 are for the forget gate.</li>
<li>paramID 2 and 6 are for the output gate.</li>
<li>paramID 3 and 7 are for the new memory gate.</li>
</ul>
<p>For miopenGRU paramID 0 to 2 refer to the weight matrix offset associated with the input GEMM, while 3 through 5 are associated with the hidden state GEMM.</p>
<ul>
<li>paramID 0 and 3 are for the update gate.</li>
<li>paramID 1 and 4 are for the reset gate.</li>
<li>paramID 2 and 5 are for the new memory gate.</li>
</ul>
<p>For bi-directional RNNs the backwards in time direction is numbered as the layer directly after the forward in time direction.</p>
<p>The output argument paramDesc is a previously created tensor descriptor that is populated to describe the memory layout of the parameter matrix. It is full packed and is used when calling to <a class="el" href="group___r_n_n.html#gaa13b97d4ebe9960126140e7838701e13" title="Sets a weight matrix for a specific layer in an RNN stack.">miopenSetRNNLayerParam()</a>.</p>
<p>The argument layerParamOffset should either be nullptr, or an address to place the offset. If layerParamOffset is nullptr then only the paramDesc is populated and returned.</p>
<p>Note: When inputSkip mode is selected there is no input layer matrix operation, and therefore no associated memory. In this case <a class="el" href="group___r_n_n.html#ga2c445114d21ef806585c4de8fe777b70" title="Gets an index offset for a specific weight matrix for a layer in the RNN stack.">miopenGetRNNLayerParamOffset()</a> will return a error status miopenStatusBadParm for input paramID associated with the input GEMM.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">layer</td><td>The layer number in the RNN stack (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A tensor descriptor to input (input) </td></tr>
    <tr><td class="paramname">paramID</td><td>ID of the internal parameter tensor (input) </td></tr>
    <tr><td class="paramname">paramDesc</td><td>Tensor descriptor for the fully packed output parameter tensor (output) </td></tr>
    <tr><td class="paramname">layerParamOffset</td><td>Location for the parameter offset (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a324">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gab082ab70bd71d3d5a248b76bf96def6b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab082ab70bd71d3d5a248b76bf96def6b">&#9670;&nbsp;</a></span>miopenGetRNNLayerParamSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNLayerParamSize </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>paramID</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>numBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Gets the number of bytes of a parameter matrix. </p>
<p>For RNN vanilla miopenRNNRELU and miopenRNNTANH, paramID == 0 retrieves the weight matrix associated with the in input GEMM, while paramID == 1 retrieves the weight matrix associated with the hidden state GEMM.</p>
<p>For miopenLSTM paramID 0 to 3 refer to the weight matrices associated with the input GEMM, 4-7 are associated with matrices associated with the hidden state GEMM.</p>
<ul>
<li>paramID 0 and 4 are for the input gate.</li>
<li>paramID 1 and 5 are for the forget gate.</li>
<li>paramID 2 and 6 are for the output gate.</li>
<li>paramID 3 and 7 are for the new memory gate.</li>
</ul>
<p>For miopenGRU paramID 0 to 2 refer to the weight matrix offset associated with the input GEMM, while 3 through 5 are associated with the hidden state GEMM.</p>
<ul>
<li>paramID 0 and 3 are for the update gate.</li>
<li>paramID 1 and 4 are for the reset gate.</li>
<li>paramID 2 and 5 are for the new memory gate.</li>
</ul>
<p>For bi-directional RNNs the backwards in time direction is numbered as the layer directly after the forward in time direction.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">layer</td><td>The layer number in the RNN stack (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A tensor descriptor to input (input) </td></tr>
    <tr><td class="paramname">paramID</td><td>ID of the internal parameter tensor (input) </td></tr>
    <tr><td class="paramname">numBytes</td><td>The number of bytes of the layer's parameter matrix (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a320">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga86fc04d775ab501c0ab829703b2cf738"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga86fc04d775ab501c0ab829703b2cf738">&#9670;&nbsp;</a></span>miopenGetRNNPaddingMode()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNPaddingMode </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#gaeb0b6dbeefb776e9b663c66a247a7121">miopenRNNPaddingMode_t</a> *&#160;</td>
          <td class="paramname"><em>paddingMode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function retrieves the RNN padding mode from the RNN descriptor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">paddingMode</td><td>Pointer to the RNN padding mode (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a329">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gadf75eb328f82b81ddc83d4230b0c54af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gadf75eb328f82b81ddc83d4230b0c54af">&#9670;&nbsp;</a></span>miopenGetRNNParamsDescriptor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNParamsDescriptor </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>wDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a>&#160;</td>
          <td class="paramname"><em>dtype</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Obtain a weight tensor descriptor for RNNs. </p>
<p>This function populates a weight descriptor that describes the memory layout of the weight matrix.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>Fully populated RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A previously populated tensor descriptor (input) </td></tr>
    <tr><td class="paramname">wDesc</td><td>A previously allocated tensor descriptor (output) </td></tr>
    <tr><td class="paramname">dtype</td><td>MIOpen data type enum (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a317">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga2394f4629b6da29bf2145f0e0220810c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2394f4629b6da29bf2145f0e0220810c">&#9670;&nbsp;</a></span>miopenGetRNNParamsSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNParamsSize </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>numBytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a>&#160;</td>
          <td class="paramname"><em>dtype</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Query the amount of parameter memory required for RNN training. </p>
<p>This function calculates the amount of parameter memory required to train the RNN layer given an RNN descriptor and a tensor descriptor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A tensor descriptor (input) </td></tr>
    <tr><td class="paramname">numBytes</td><td>Number of bytes required for RNN layer execution (output) </td></tr>
    <tr><td class="paramname">dtype</td><td>MIOpen data type enum (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a316">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga82cf9678664959b494765e56f06f87c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga82cf9678664959b494765e56f06f87c3">&#9670;&nbsp;</a></span>miopenGetRNNTempSpaceSizes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNTempSpaceSizes </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga9e0d9408f321de068cc30ad5a7de778b">miopenRNNFWDMode_t</a>&#160;</td>
          <td class="paramname"><em>fwdMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>workSpaceSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>reserveSpaceSize</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Query the amount of additional memory required for this RNN layer execution. </p>
<p>This function calculates the size of extra buffers, depending on the layer configuration, which is determined by: RNN descriptor, isInference, and data descriptor. If isInference is True, reserve_space_size is always zero, because the reserve_space buffer is not used in Inference computation.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>Sequence data tensor descriptor (input) </td></tr>
    <tr><td class="paramname">fwdMode</td><td>Specifies in which mode the buffers will be used. </td></tr>
    <tr><td class="paramname">workSpaceSize</td><td>Minimum WorkSpace buffer size required for RNN layer execution (output) </td></tr>
    <tr><td class="paramname">reserveSpaceSize</td><td>Minimum ReserveSpaceSize buffer size required for RNN layer execution (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a315">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga59b770093f4ab10d72126436b1d0395a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga59b770093f4ab10d72126436b1d0395a">&#9670;&nbsp;</a></span>miopenGetRNNTrainingReserveSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNTrainingReserveSize </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>sequenceLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>numBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Query the amount of memory required for RNN training. </p>
<p>This function calculates the amount of memory required to train the RNN layer given an RNN descriptor and a tensor descriptor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">sequenceLen</td><td>Number of iteration unrolls (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>An array of tensor descriptors. These are the input descriptors to each time step. The first dimension of each descriptor is the batch size and may decrease from element n to element n+1 and not increase in size. The second dimension is the same for all descriptors in the array and is the input vector length. (input) </td></tr>
    <tr><td class="paramname">numBytes</td><td>Number of bytes required for RNN layer execution (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a314">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gad2f8db58662277452612e0b3381123fe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad2f8db58662277452612e0b3381123fe">&#9670;&nbsp;</a></span>miopenGetRNNWorkspaceSize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenGetRNNWorkspaceSize </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>sequenceLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t *&#160;</td>
          <td class="paramname"><em>numBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Query the amount of memory required to execute the RNN layer. </p>
<p>This function calculates the amount of memory required to run the RNN layer given an RNN descriptor and a tensor descriptor.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">sequenceLen</td><td>Number of iteration unrolls (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>An array of tensor descriptors. These are the input descriptors to each time step. The first dimension of each descriptor is the batch size and may decrease from element n to element n+1 and not increase in size. The second dimension is the same for all descriptors in the array and is the input vector length. (input) </td></tr>
    <tr><td class="paramname">numBytes</td><td>Number of bytes required for RNN layer execution (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a313">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga6ac03fa91d038feb1206b4f8a770af97"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6ac03fa91d038feb1206b4f8a770af97">&#9670;&nbsp;</a></span>miopenRNNBackwardData()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenRNNBackwardData </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>sequenceLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>yDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>dyDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>dy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>dhyDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>dhy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>dcyDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>dcy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>wDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>hx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>cxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>cx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>dxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>dx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>dhxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>dhx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>dcxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>dcx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>workSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>workSpaceNumBytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>reserveSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>reserveSpaceNumBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execute backward data for recurrent layer. </p>
<p>Interface for executing the backward data pass on a RNN.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">sequenceLen</td><td>Temporal iterations to unroll (input) </td></tr>
    <tr><td class="paramname">yDesc</td><td>An array of tensor descriptors (input) </td></tr>
    <tr><td class="paramname">y</td><td>Pointer to input tensor (input) </td></tr>
    <tr><td class="paramname">dyDesc</td><td>An array of fully packed tensor descriptors associated with the output from each time step. The first dimension of the tensor descriptors must equal the first dimension of the first descriptor (batch size) in the xDesc tensor array. The second dimension of the element of the descriptor array depends on the direction mode selected. If the direction mode is unidirectional, the second dimension is the hiddenSize. If direction mode is bidirectional the second dimension is twice the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">dy</td><td>Pointer to the hidden layer input tensor (input) </td></tr>
    <tr><td class="paramname">dhyDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">dhy</td><td>Pointer to the cell layer input tensor (input) </td></tr>
    <tr><td class="paramname">dcyDesc</td><td>A cell tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">dcy</td><td>Pointer to the cell layer input tensor. If dcy is NULL, then the initial delta cell state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">wDesc</td><td>A weights tensor descriptor (input) </td></tr>
    <tr><td class="paramname">w</td><td>Pointer to input weights tensor (input) </td></tr>
    <tr><td class="paramname">hxDesc</td><td>An input hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hx</td><td>Pointer to the hidden layer input tensor. If hx is NULL, then the initial hidden state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">cxDesc</td><td>A input cell tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">cx</td><td>Pointer to the hidden layer input tensor. If cx is NULL, then the initial cell state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">dxDesc</td><td>An array of tensor descriptors. These are the input descriptors to each time step. The first dimension of each descriptor is the batch size and may decrease from element n to element n+1 and not increase in size. The second dimension is the same for all descriptors in the array and is the input vector length. (input) </td></tr>
    <tr><td class="paramname">dx</td><td>Pointer to the cell layer output tensor (output) </td></tr>
    <tr><td class="paramname">dhxDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">dhx</td><td>Pointer to the delta hidden layer output tensor. If dhx is NULL the hidden gradient will not ouput. (output) </td></tr>
    <tr><td class="paramname">dcxDesc</td><td>A tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">dcx</td><td>Pointer to the cell layer output tensor. If dcx is NULL the cell gradient will not ouput. (output) </td></tr>
    <tr><td class="paramname">workSpace</td><td>Pointer to memory allocated for forward training (input) </td></tr>
    <tr><td class="paramname">workSpaceNumBytes</td><td>Number of allocated bytes in memory for the workspace (input) </td></tr>
    <tr><td class="paramname">reserveSpace</td><td>Pointer to memory allocated for random states (input / output) </td></tr>
    <tr><td class="paramname">reserveSpaceNumBytes</td><td>Number of allocated bytes in memory for use in the forward (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a334">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga44ac8be6fceea4aa1e755958960be862"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga44ac8be6fceea4aa1e755958960be862">&#9670;&nbsp;</a></span>miopenRNNBackwardSeqData()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenRNNBackwardSeqData </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>yDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>dy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>hx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>dhy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>dhx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>cDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>cx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>dcy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>dcx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>dx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>weightSpaceSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>workSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>workSpaceNumBytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>reserveSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>reserveSpaceNumBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execute backward data for recurrent layer. </p>
<p>Interface for executing the backward data pass on a RNN.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input)</td></tr>
    <tr><td class="paramname">yDesc</td><td>An output tensor descriptor for sequenced RNN data. This miopenSeqTensorDescriptor_t should be initialyzed by <code>miopenSetRNNDataSeqTensorDescriptor</code> function.(input) </td></tr>
    <tr><td class="paramname">y</td><td>Pointer to input tensor (input) </td></tr>
    <tr><td class="paramname">dy</td><td>Pointer to the hidden layer input tensor (input)</td></tr>
    <tr><td class="paramname">hDesc</td><td>An input hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hx</td><td>Pointer to the hidden layer input tensor. If hx is NULL, then the initial hidden state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">dhy</td><td>Pointer to the cell layer input tensor (input) </td></tr>
    <tr><td class="paramname">dhx</td><td>Pointer to the delta hidden layer output tensor. If dhx is NULL the hidden gradient will not ouput. (output)</td></tr>
    <tr><td class="paramname">cDesc</td><td>A input cell tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">cx</td><td>Pointer to the hidden layer input tensor. If cx is NULL, then the initial cell state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">dcy</td><td>Pointer to the cell layer input tensor. If dcy is NULL, then the initial delta cell state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">dcx</td><td>Pointer to the cell layer output tensor. If dcx is NULL the cell gradient will not ouput. (output)</td></tr>
    <tr><td class="paramname">xDesc</td><td>An input tensor descriptor for sequenced RNN data. This miopenSeqTensorDescriptor_t should be initialyzed by <code>miopenSetRNNDataSeqTensorDescriptor</code> function.(input) </td></tr>
    <tr><td class="paramname">dx</td><td>Pointer to the cell layer output tensor (output)</td></tr>
    <tr><td class="paramname">w</td><td>Pointer to input weights tensor (input) </td></tr>
    <tr><td class="paramname">weightSpaceSize</td><td>Number of allocated bytes in memory for the weights tensor </td></tr>
    <tr><td class="paramname">workSpace</td><td>Pointer to memory allocated for forward training (input) </td></tr>
    <tr><td class="paramname">workSpaceNumBytes</td><td>Number of allocated bytes in memory for the workspace (input) </td></tr>
    <tr><td class="paramname">reserveSpace</td><td>Pointer to memory allocated for random states (input / output) </td></tr>
    <tr><td class="paramname">reserveSpaceNumBytes</td><td>Number of allocated bytes in memory for use in the forward (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a331">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga55040b58e6820d21f58957d356715739"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga55040b58e6820d21f58957d356715739">&#9670;&nbsp;</a></span>miopenRNNBackwardWeights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenRNNBackwardWeights </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>sequenceLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>hx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>yDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>dwDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>dw</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>workSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>workSpaceNumBytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>reserveSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>reserveSpaceNumBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execute backward weights for recurrent layer. </p>
<p>Interface for executing the backward weights pass on a RNN.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">sequenceLen</td><td>Temporal iterations to unroll (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>An array of tensor descriptors. These are the input descriptors to each time step. The first dimension of each descriptor is the batch size and may decrease from element n to element n+1 and not increase in size. The second dimension is the same for all descriptors in the array and is the input vector length. (input) </td></tr>
    <tr><td class="paramname">x</td><td>Pointer to input tensor (input) </td></tr>
    <tr><td class="paramname">hxDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hx</td><td>Pointer to the hidden layer input tensor. If hx is NULL, then the initial hidden state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">yDesc</td><td>An array of fully packed tensor descriptors associated with the output from each time step. The first dimension of the tensor descriptors must equal the first dimension of the first descriptor (batch size) in the xDesc tensor array. The second dimension of the element of the descriptor array depends on the direction mode selected. If the direction mode is unidirectional, the second dimension is the hiddenSize. If direction mode is bidirectional the second dimension is twice the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">y</td><td>Pointer to the output tensor (input) </td></tr>
    <tr><td class="paramname">dwDesc</td><td>A weights tensor descriptor (input) </td></tr>
    <tr><td class="paramname">dw</td><td>Pointer to input weights tensor (input / output) </td></tr>
    <tr><td class="paramname">workSpace</td><td>Pointer to memory allocated for forward training (input) </td></tr>
    <tr><td class="paramname">workSpaceNumBytes</td><td>Number of allocated bytes in memory for the workspace (input) </td></tr>
    <tr><td class="paramname">reserveSpace</td><td>Pointer to memory allocated for random states (input) </td></tr>
    <tr><td class="paramname">reserveSpaceNumBytes</td><td>Number of allocated bytes in memory for use in the forward (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a335">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga1ff33e5279bfca3ed08d59bfa8069a9d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1ff33e5279bfca3ed08d59bfa8069a9d">&#9670;&nbsp;</a></span>miopenRNNBackwardWeightsSeqTensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenRNNBackwardWeightsSeqTensor </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>hx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>yDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>dw</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>weightSpaceSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>workSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>workSpaceNumBytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>reserveSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>reserveSpaceNumBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execute backward weights for recurrent layer. </p>
<p>Interface for executing the backward weights pass on a RNN.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input)</td></tr>
    <tr><td class="paramname">xDesc</td><td>An input tensor descriptor for sequenced RNN data. This miopenSeqTensorDescriptor_t should be initialyzed by <code>miopenSetRNNDataSeqTensorDescriptor</code> function.(input) </td></tr>
    <tr><td class="paramname">x</td><td>Pointer to input tensor (input)</td></tr>
    <tr><td class="paramname">hDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hx</td><td>Pointer to the hidden layer input tensor. If hx is NULL, then the initial hidden state will be zero initialized. (input)</td></tr>
    <tr><td class="paramname">yDesc</td><td>An output tensor descriptor for sequenced RNN data. This miopenSeqTensorDescriptor_t should be initialyzed by <code>miopenSetRNNDataSeqTensorDescriptor</code> function.(input) </td></tr>
    <tr><td class="paramname">y</td><td>Pointer to the output tensor (input)</td></tr>
    <tr><td class="paramname">dw</td><td>Pointer to input weights tensor (input / output) </td></tr>
    <tr><td class="paramname">weightSpaceSize</td><td>Number of allocated bytes in memory for the weights tensor </td></tr>
    <tr><td class="paramname">workSpace</td><td>Pointer to memory allocated for forward training (input) </td></tr>
    <tr><td class="paramname">workSpaceNumBytes</td><td>Number of allocated bytes in memory for the workspace (input) </td></tr>
    <tr><td class="paramname">reserveSpace</td><td>Pointer to memory allocated for random states (input) </td></tr>
    <tr><td class="paramname">reserveSpaceNumBytes</td><td>Number of allocated bytes in memory for use in the forward (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a332">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga8d5b72681258d9cd7f50ba03ab6215e5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8d5b72681258d9cd7f50ba03ab6215e5">&#9670;&nbsp;</a></span>miopenRNNForward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenRNNForward </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga9e0d9408f321de068cc30ad5a7de778b">miopenRNNFWDMode_t</a>&#160;</td>
          <td class="paramname"><em>fwdMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>hx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>hy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>cDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>cx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>cy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>yDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>weightSpaceSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>workSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>workSpaceNumBytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>reserveSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>reserveSpaceNumBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execute forward training for recurrent layer. </p>
<p>Interface for executing the forward training / inference pass on a RNN.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">fwdMode</td><td>Specifies in which mode the buffers will be used. </td></tr>
    <tr><td class="paramname">xDesc</td><td>An input tensor descriptor for sequenced RNN data. This miopenSeqTensorDescriptor_t should be initialyzed by <code>miopenSetRNNDataSeqTensorDescriptor</code> function.(input) </td></tr>
    <tr><td class="paramname">x</td><td>Pointer to input tensor (input)</td></tr>
    <tr><td class="paramname">hDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hx</td><td>Pointer to the hidden layer input tensor. If hx is NULL, then the initial hidden state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">hy</td><td>Pointer to the hidden layer output tensor. If hy is NULL, then the final hidden state will not be saved. (output)</td></tr>
    <tr><td class="paramname">cDesc</td><td>A cell tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">cx</td><td>Pointer to the cell layer input tensor. If cx is NULL, then the initial cell state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">cy</td><td>Pointer to the cell layer output tensor. If hy is NULL, then the final cell state will not be saved. (output)</td></tr>
    <tr><td class="paramname">yDesc</td><td>An array of fully packed tensor descriptors associated with the output from each time step. The first dimension of the tensor descriptors must equal the first dimension of the first descriptor (batch size) in the xDesc tensor array. The second dimension of the element of the descriptor array depends on the direction mode selected. If the direction mode is unidirectional, the second dimension is the hiddenSize. If direction mode is bidirectional the second dimension is twice the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">y</td><td>Pointer to output tensor (output)</td></tr>
    <tr><td class="paramname">w</td><td>Pointer to input weights tensor (input) </td></tr>
    <tr><td class="paramname">weightSpaceSize</td><td>Number of allocated bytes in memory for the weights tensor </td></tr>
    <tr><td class="paramname">workSpace</td><td>Pointer to memory allocated for forward (input / output) </td></tr>
    <tr><td class="paramname">workSpaceNumBytes</td><td>Number of allocated bytes in memory for the workspace (input) </td></tr>
    <tr><td class="paramname">reserveSpace</td><td>Pointer to memory allocated for hidden states used durning training (input / output) </td></tr>
    <tr><td class="paramname">reserveSpaceNumBytes</td><td>Number of allocated bytes in memory for use in the forward (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a330">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gafd8f2c43d92a7baf7de2e431bbcf7199"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gafd8f2c43d92a7baf7de2e431bbcf7199">&#9670;&nbsp;</a></span>miopenRNNForwardInference()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenRNNForwardInference </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>sequenceLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>hx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>cxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>cx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>wDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>yDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hyDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>hy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>cyDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>cy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>workSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>workSpaceNumBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execute forward inference for RNN layer. </p>
<p>Interface for executing the forward inference pass on a RNN.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">sequenceLen</td><td>Temporal iterations to unroll (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>An array of tensor descriptors. These are the input descriptors to each time step. The first dimension of each descriptor is the batch size and may decrease from element n to element n+1 and not increase in size. The second dimension is the same for all descriptors in the array and is the input vector length. (input) </td></tr>
    <tr><td class="paramname">x</td><td>Pointer to input tensor (input) </td></tr>
    <tr><td class="paramname">hxDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hx</td><td>Pointer to the hidden layer input tensor. If hx is NULL, then the initial hidden state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">cxDesc</td><td>A cell tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">cx</td><td>Pointer to the cell layer input tensor. If cx is NULL, then the initial cell state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">wDesc</td><td>A weights tensor descriptor (input) </td></tr>
    <tr><td class="paramname">w</td><td>Pointer to input weights tensor (input) </td></tr>
    <tr><td class="paramname">yDesc</td><td>An array of fully packed tensor descriptors associated with the output from each time step. The first dimension of the tensor descriptors must equal the first dimension of the first descriptor (batch size) in the xDesc tensor array. The second dimension of the element of the descriptor array depends on the direction mode selected. If the direction mode is unidirectional, the second dimension is the hiddenSize. If direction mode is bidirectional the second dimension is twice the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">y</td><td>Pointer to output tensor (output) </td></tr>
    <tr><td class="paramname">hyDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hy</td><td>Pointer to the hidden layer output tensor. If hy is NULL, then the final hidden state will not be saved. (output) </td></tr>
    <tr><td class="paramname">cyDesc</td><td>A output cell tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">cy</td><td>Pointer to the cell layer output tensor. If cy is NULL, then the final cell state will not be saved. (output) </td></tr>
    <tr><td class="paramname">workSpace</td><td>Pointer to memory allocated for forward training (input) </td></tr>
    <tr><td class="paramname">workSpaceNumBytes</td><td>Number of allocated bytes in memory for the workspace (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a336">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gae7844191464b02e0343af135904413ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae7844191464b02e0343af135904413ab">&#9670;&nbsp;</a></span>miopenRNNForwardTraining()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenRNNForwardTraining </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>sequenceLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>hx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>cxDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>cx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>wDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t *&#160;</td>
          <td class="paramname"><em>yDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>hyDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>hy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>cyDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>cy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>workSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>workSpaceNumBytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>reserveSpace</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>reserveSpaceNumBytes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execute forward training for recurrent layer. </p>
<p>Interface for executing the forward training pass on a RNN.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">sequenceLen</td><td>Temporal iterations to unroll (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>An array of tensor descriptors. These are the input descriptors to each time step. The first dimension of each descriptor is the batch size and may decrease from element n to element n+1 and not increase in size. The second dimension is the same for all descriptors in the array and is the input vector length. (input) </td></tr>
    <tr><td class="paramname">x</td><td>Pointer to input tensor (input) </td></tr>
    <tr><td class="paramname">hxDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hx</td><td>Pointer to the hidden layer input tensor. If hx is NULL, then the initial hidden state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">cxDesc</td><td>A cell tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">cx</td><td>Pointer to the cell layer input tensor. If cx is NULL, then the initial cell state will be zero initialized. (input) </td></tr>
    <tr><td class="paramname">wDesc</td><td>A weights tensor descriptor (input) </td></tr>
    <tr><td class="paramname">w</td><td>Pointer to input weights tensor (input) </td></tr>
    <tr><td class="paramname">yDesc</td><td>An array of fully packed tensor descriptors associated with the output from each time step. The first dimension of the tensor descriptors must equal the first dimension of the first descriptor (batch size) in the xDesc tensor array. The second dimension of the element of the descriptor array depends on the direction mode selected. If the direction mode is unidirectional, the second dimension is the hiddenSize. If direction mode is bidirectional the second dimension is twice the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">y</td><td>Pointer to output tensor (output) </td></tr>
    <tr><td class="paramname">hyDesc</td><td>A hidden tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">hy</td><td>Pointer to the hidden layer output tensor. If hy is NULL, then the final hidden state will not be saved. (output) </td></tr>
    <tr><td class="paramname">cyDesc</td><td>A cell tensor descriptor that has as its first dimension of the number of layers if the direction mode is unidirectional and twice the number of layers if the direction mode is bidirectional. The second dimension of the descriptor must equal the largest first dimension of the xDesc tensor descriptor array. The third dimension equals the hiddenSize. (input) </td></tr>
    <tr><td class="paramname">cy</td><td>Pointer to the cell layer output tensor. If hy is NULL, then the final cell state will not be saved. (output) </td></tr>
    <tr><td class="paramname">workSpace</td><td>Pointer to memory allocated for forward training (input) </td></tr>
    <tr><td class="paramname">workSpaceNumBytes</td><td>Number of allocated bytes in memory for the workspace (input) </td></tr>
    <tr><td class="paramname">reserveSpace</td><td>Pointer to memory allocated for random states (input / output) </td></tr>
    <tr><td class="paramname">reserveSpaceNumBytes</td><td>Number of allocated bytes in memory for use in the forward (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a333">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gadaf0448f9d4ee351183c7e83d2b5f520"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gadaf0448f9d4ee351183c7e83d2b5f520">&#9670;&nbsp;</a></span>miopenSetRNNDataSeqTensorDescriptor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenSetRNNDataSeqTensorDescriptor </td>
          <td>(</td>
          <td class="paramtype">miopenSeqTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>seqTensorDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a>&#160;</td>
          <td class="paramname"><em>dataType</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga637e3f078445cce6869966a46e1a486f">miopenRNNBaseLayout_t</a>&#160;</td>
          <td class="paramname"><em>layout</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>maxSequenceLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batchSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>vectorSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int *&#160;</td>
          <td class="paramname"><em>sequenceLenArray</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>paddingMarker</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set shape of RNN seqData tensor. </p>
<p>Interface for setting tensor shape to be used as RNN input data</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">seqTensorDesc</td><td>Tensor descriptor (input/output) </td></tr>
    <tr><td class="paramname">dataType</td><td>MIOpen datatype (input) </td></tr>
    <tr><td class="paramname">layout</td><td>One of the main supported layouts for RNN data(input) </td></tr>
    <tr><td class="paramname">maxSequenceLen</td><td>Sequence length limit within this SeqTensor(input) </td></tr>
    <tr><td class="paramname">batchSize</td><td>Number of sequences within this SeqTensor (input) </td></tr>
    <tr><td class="paramname">vectorSize</td><td>Vector size (input) </td></tr>
    <tr><td class="paramname">sequenceLenArray</td><td>Array containing the length of each sequence in the SeqTensor(input) </td></tr>
    <tr><td class="paramname">paddingMarker</td><td>Not used, should be NULL (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a311">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga609253972613b2dc6ea2e9d07697f665"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga609253972613b2dc6ea2e9d07697f665">&#9670;&nbsp;</a></span>miopenSetRNNDescriptor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenSetRNNDescriptor </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>hsize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>nlayers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a>&#160;</td>
          <td class="paramname"><em>inMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a>&#160;</td>
          <td class="paramname"><em>direction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a>&#160;</td>
          <td class="paramname"><em>rnnMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a>&#160;</td>
          <td class="paramname"><em>biasMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a>&#160;</td>
          <td class="paramname"><em>algo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a>&#160;</td>
          <td class="paramname"><em>dataType</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set the details of the RNN descriptor. </p>
<p>Interface for setting the values of the RNN descriptor object. This function requires specific algorithm selection. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">hsize</td><td>Hidden layer size (input) </td></tr>
    <tr><td class="paramname">nlayers</td><td>Number of layers (input) </td></tr>
    <tr><td class="paramname">inMode</td><td>RNN first layer input mode (input) </td></tr>
    <tr><td class="paramname">direction</td><td>RNN direction (input) </td></tr>
    <tr><td class="paramname">rnnMode</td><td>RNN model type (input) </td></tr>
    <tr><td class="paramname">biasMode</td><td>RNN bias included (input) </td></tr>
    <tr><td class="paramname">algo</td><td>RNN algorithm selected (input) </td></tr>
    <tr><td class="paramname">dataType</td><td>MIOpen datatype (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a309">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gaf02ff9a9c328099753d9244eae95c5d6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf02ff9a9c328099753d9244eae95c5d6">&#9670;&nbsp;</a></span>miopenSetRNNDescriptor_V2()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenSetRNNDescriptor_V2 </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>hsize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>nlayers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenDropoutDescriptor_t&#160;</td>
          <td class="paramname"><em>dropoutDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga11808e1b616d9b9d7e6c701986783af7">miopenRNNInputMode_t</a>&#160;</td>
          <td class="paramname"><em>inMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga3c7adae8941033d266f1d5e029504c38">miopenRNNDirectionMode_t</a>&#160;</td>
          <td class="paramname"><em>direction</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga016f266507f199def908fe39c43d7877">miopenRNNMode_t</a>&#160;</td>
          <td class="paramname"><em>rnnMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga47b037e570937a567de38e8898a99f37">miopenRNNBiasMode_t</a>&#160;</td>
          <td class="paramname"><em>biasMode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#ga6bca6bf2c239cb387d99a07cb6b331c4">miopenRNNAlgo_t</a>&#160;</td>
          <td class="paramname"><em>algo</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__tensor.html#ga8bf94a23997093548ddf866c94c4ac17">miopenDataType_t</a>&#160;</td>
          <td class="paramname"><em>dataType</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set the details of the RNN descriptor version 2. This version enables the use of dropout in rnn. </p>
<p>Interface for setting the values of the RNN descriptor object. This function requires specific algorithm selection. </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input/output) </td></tr>
    <tr><td class="paramname">hsize</td><td>Hidden layer size (input) </td></tr>
    <tr><td class="paramname">nlayers</td><td>Number of layers (input) </td></tr>
    <tr><td class="paramname">dropoutDesc</td><td>Pre-initialized dropout descriptor for dropout layer in between RNN layers (input) </td></tr>
    <tr><td class="paramname">inMode</td><td>RNN first layer input mode (input) </td></tr>
    <tr><td class="paramname">direction</td><td>RNN direction (input) </td></tr>
    <tr><td class="paramname">rnnMode</td><td>RNN model type (input) </td></tr>
    <tr><td class="paramname">biasMode</td><td>RNN bias included (input) </td></tr>
    <tr><td class="paramname">algo</td><td>RNN algorithm selected (input) </td></tr>
    <tr><td class="paramname">dataType</td><td>MIOpen datatype (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a310">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="ga1991ee70fba68f8de643c1a4aa183bf7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1991ee70fba68f8de643c1a4aa183bf7">&#9670;&nbsp;</a></span>miopenSetRNNLayerBias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenSetRNNLayerBias </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>wDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>biasID</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>biasDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>layerBias</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets a bias for a specific layer in an RNN stack. </p>
<p>This function sets the bias data for a specific layer and bias ID.</p>
<p>For RNN vanilla miopenRNNRELU and miopenRNNTANH, biasID == 0 retrieves the weight matrix associated with the in input GEMM, while biasID == 1 retrieves the bias associated with the hidden state GEMM.</p>
<p>For miopenLSTM biasID 0 to 3 refer to the biases associated with the input GEMM, 4-7 are associated with the biases associated with the hidden state GEMM.</p>
<ul>
<li>biasID 0 and 4 are for the input gate.</li>
<li>biasID 1 and 5 are for the forget gate.</li>
<li>biasID 2 and 6 are for the output gate.</li>
<li>biasID 3 and 7 are for the new memory gate.</li>
</ul>
<p>For miopenGRU biasID 0 to 2 refer to the biases associated with the input GEMM, while 3 through 5 are associated with the hidden state GEMM.</p>
<ul>
<li>biasID 0 and 3 are for the update gate.</li>
<li>biasID 1 and 4 are for the reset gate.</li>
<li>biasID 2 and 5 are for the new new memory gate.</li>
</ul>
<p>For bi-directional RNNs the backwards in time direction is numbered as the layer directly after the forward in time direction.</p>
<p>The input argument biasDesc is a previously populated tensor descriptor typically by first calling miopenGetRNNLayeBias().</p>
<p>Note: When inputSkip mode is selected there is no input layer matrix operation, and therefore no associated memory. In this case miopenSetRNNLayerBias will return a error status miopenStatusBadParm for input biasID associated with the input GEMM.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">layer</td><td>The layer number in the RNN stack (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A tensor descriptor to input (input) </td></tr>
    <tr><td class="paramname">wDesc</td><td>A tensor descriptor to the bias tensor (input) </td></tr>
    <tr><td class="paramname">w</td><td>Pointer to memory containing bias tensor (input) </td></tr>
    <tr><td class="paramname">biasID</td><td>ID of the internal bias tensor (input) </td></tr>
    <tr><td class="paramname">biasDesc</td><td>Descriptor of the bias tensor (output) </td></tr>
    <tr><td class="paramname">layerBias</td><td>Pointer to the memory location of the bias tensor (output) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a327">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gaa13b97d4ebe9960126140e7838701e13"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa13b97d4ebe9960126140e7838701e13">&#9670;&nbsp;</a></span>miopenSetRNNLayerParam()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenSetRNNLayerParam </td>
          <td>(</td>
          <td class="paramtype">miopenHandle_t&#160;</td>
          <td class="paramname"><em>handle</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>xDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>wDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>paramID</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">miopenTensorDescriptor_t&#160;</td>
          <td class="paramname"><em>paramDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>layerParam</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets a weight matrix for a specific layer in an RNN stack. </p>
<p>This function sets the weight matrix data for a specific layer and parameter ID.</p>
<p>For RNN vanilla miopenRNNRELU and miopenRNNTANH, paramID == 0 sets the weight matrix associated with the in input GEMM, while paramID == 1 sets the weight matrix associated with the hidden state GEMM.</p>
<p>For miopenLSTM paramID 0 to 3 refer to the weight matrices associated with the input GEMM, 4-7 are associated with matrices associated with the hidden state GEMM.</p>
<ul>
<li>paramID 0 and 4 are for the input gate.</li>
<li>paramID 1 and 5 are for the forget gate.</li>
<li>paramID 2 and 6 are for the output gate.</li>
<li>paramID 3 and 7 are for the new memory gate.</li>
</ul>
<p>For miopenGRU paramID 0 to 2 refer to the weight matrix offset associated with the input GEMM, while 3 through 5 are associated with the hidden state GEMM.</p>
<ul>
<li>paramID 0 and 3 are for the update gate.</li>
<li>paramID 1 and 4 are for the reset gate.</li>
<li>paramID 2 and 5 are for the new memory gate.</li>
</ul>
<p>For bi-directional RNNs the backwards in time direction is numbered as the layer directly after the forward in time direction.</p>
<p>The input argument paramDesc is a previously populated tensor descriptor typically by first calling <a class="el" href="group___r_n_n.html#gacd0730d483c86d3f9f047658a58f5695" title="Gets a weight matrix for a specific layer in an RNN stack.">miopenGetRNNLayerParam()</a>.</p>
<p>Note: When inputSkip mode is selected there is no input layer matrix operation, and therefore no associated memory. In this case <a class="el" href="group___r_n_n.html#gaa13b97d4ebe9960126140e7838701e13" title="Sets a weight matrix for a specific layer in an RNN stack.">miopenSetRNNLayerParam()</a> will return a error status miopenStatusBadParm for input paramID associated with the input GEMM.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">handle</td><td>MIOpen handle (input) </td></tr>
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input) </td></tr>
    <tr><td class="paramname">layer</td><td>The layer number in the RNN stack (input) </td></tr>
    <tr><td class="paramname">xDesc</td><td>A tensor descriptor to input (input) </td></tr>
    <tr><td class="paramname">wDesc</td><td>A tensor descriptor to the parameter tensor (input) </td></tr>
    <tr><td class="paramname">w</td><td>Pointer to memory containing parameter tensor (input) </td></tr>
    <tr><td class="paramname">paramID</td><td>ID of the internal parameter tensor (input) </td></tr>
    <tr><td class="paramname">paramDesc</td><td>Descriptor of the parameter tensor (input) </td></tr>
    <tr><td class="paramname">layerParam</td><td>Pointer to the memory location of the parameter tensor (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a326">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
<a id="gaf9f746d7c62bfbf62ff8663e54360771"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf9f746d7c62bfbf62ff8663e54360771">&#9670;&nbsp;</a></span>miopenSetRNNPaddingMode()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__handle.html#ga74216ea6ba6c5487d5aceb46eb35f1d6">miopenStatus_t</a> miopenSetRNNPaddingMode </td>
          <td>(</td>
          <td class="paramtype">miopenRNNDescriptor_t&#160;</td>
          <td class="paramname"><em>rnnDesc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___r_n_n.html#gaeb0b6dbeefb776e9b663c66a247a7121">miopenRNNPaddingMode_t</a>&#160;</td>
          <td class="paramname"><em>paddingMode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets a bias for a specific layer in an RNN stack. </p>
<p>This function changes padidng mode at previously created and initialized RNN descriptor. This function must be called before using <a class="el" href="group___r_n_n.html#gad2f8db58662277452612e0b3381123fe" title="Query the amount of memory required to execute the RNN layer.">miopenGetRNNWorkspaceSize()</a> and <a class="el" href="group___r_n_n.html#ga59b770093f4ab10d72126436b1d0395a" title="Query the amount of memory required for RNN training.">miopenGetRNNTrainingReserveSize()</a> functions. By default, not padded data is expected at the RNN input/output.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">rnnDesc</td><td>RNN layer descriptor type (input/output) </td></tr>
    <tr><td class="paramname">paddingMode</td><td>RNN input/output data padding mode (input) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>miopenStatus_t </dd></dl>
<dl class="section examples"><dt>Examples</dt><dd><a class="el" href="_2home_2ldelaney_2_m_i_open_2include_2miopen_2miopen_8h-example.html#a328">/home/ldelaney/MIOpen/include/miopen/miopen.h</a>.</dd>
</dl>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
